\section{Related Work}
\label{sec:related}

We are not aware of any other work that attempts to selectively avoid vectorisation in higher-order programs. However, in a recent port of Blelloch's original NESL system to GPUs~\cite{bergstrom-reppy:ndp-gpu}, the code for NESL's virtual vector machine, called VCODE, is analysed to fuse sequences of lifted arithmetic operations. This is selectively \emph{undoing} some vectorisation, albeit in a first-order setting. Much like our old stream fusion system, it cannot undo the vectorisation of conditionals or recursive functions.

Manticore is an implementation of nested data parallelism that foregoes vectorisation entirely and instead relies on dynamic methods, such as work stealing and lazy tree splitting~\cite{bergstrom-etal:lts}. Similarly, Blelloch et al.~\cite{BGM99,Spoonhower:2010} investigated alternatives to flattening based on multi-threading. Based on the scheduling strategy, they were able to establish asymptotic bounds on time and space for various forms of parallelism, including nested data parallelism. 

Overall, there are two general approaches to implementing nested data parallelism. Approaches based on multi-threading naturally fit the execution model of MIMD machines, such as multicore processors. However, they need to make an effort to ensure load balancing (e.g., by using work stealing) and to agglomerate operations on successive array elements (to get efficient loops). The alternative is vectorisation, which in its pure form produces pure SIMD programs. Hence, they need to make an effort to increase locality (e.g., by array fusion). It appears as if we need a hybrid approach, and the question is whether to start from the MIMD or SIMD end. We chose to start from SIMD and relax that using vectorisation avoidance, as disucssed here, and also a more flexible array representation as discussed in a companion paper~\cite{lippmeier:work-efficient}.