\clearpage{}
\section{The Problem}
Functional programming is many things to many people, but at the heart of it is one central idea. Programs should be expressed in terms of higher order functions, referred to as \emph{combining forms} in Backus's seminal paper \cite{backus:liberate}, instead of as imperative sequences of commands which update a global store.

The folklore promises that as functional programs admit more algebraic laws than their imperative counterparts, they will be easier to express and reason about. It also promises that functional programs have the potential to run faster, with the imagined speedup being partly due to freedom from the `von Neumann bottleneck', that is sequential access to the global store, and partly due to optimising transforms which can be carried out due to the algebraic laws \cite{santos:compilation}. 

After 30 years of intense research, several industry strength compilers \cite{peyton-jones:compilation-by-transformation, nocker:clean, tofte:mlkit-4.3.0, macqueen:sml}, and countless research papers, both of these promises have been delivered on --- yet curiously, functional languages have not replaced imperative ones in mainstream software engineering.

There are a myriad of endlessly debated reasons for this apparent lack of use, and most will be quite familiar to the people likely to be reading this thesis. Often touted candidates include organisational inertia and marketing pressure exerted by large corporations seeking to cement their own particular language into the psyche of the industry programmer \cite{gosling:java-standard}. It is no doubt easy to form these opinions, especially if one is a researcher or academic in the field of programming languages. Almost by definition, we spend the majority of our time working with our own systems and attending conferences where the presentations are given by people in similar circumstances.

In recent years this situation has been recognised by the functional programming community itself, hence the creation of forums that seek to collect reports of industry experience with its languages \cite{wadler:cufp}. The conclusion of many of these presentations simply reiterates what we have known all along --- that functional programming is wonderful and the application of higher order functions, pattern matching and strong typing (for some) leads to shorter development times and more reliable software.

By all accounts the community is thriving and much software is being written, yet the majority of it continues to be from graduate students and researchers in the field of programming language theory. Of this fact one can easily be convinced by visiting an arbitrary web-based job placement agency and comparing search results for ``Haskell'' or ``O'Caml'' versus any one of ``Java'', ``Perl'', ``Ruby'', ``C++'' or ``Python''.

Are Haskell and O'Caml destined to be The Velvet Underground of programming languages, where hardly anyone has heard them, but everyone who does forms a band?\footnote{After a quote attributed to Brian Eno. The Velvet Underground were a rock music group active in the late 60's, early 70's. They were highly influential, yet initially unsuccessful in a commercial sense.}

\subsubsection{Something's missing?}
What if we were to take a step back from the glory of functional programming, and instead focus on what might be missing? After all, if functional languages could do everything that imperative languages could, \emph{as well} as having strong typing, pattern matching, higher order functions and associated goodness, then at least there would be no \emph{technically} based reason not to use them.

With this in mind, this thesis takes the position that an important missing feature from all current functional languages is real destructive update. A programmer should be free to update an arbitrary data structure in their program, with minimal runtime overhead, and with minimal interference from the type system or language design. 

Note the use of the word ``interference''. In one sense, a language is a structure for formulating and communicating ideas, but in another it is a barrier to a true expression of intent. In an imperative language the programmer can update their data when and where they see fit, whereas in a typical functional language, they cannot. We seek to remove this barrier.

This work is embodied in the Disciplined Disciple Compiler (DDC)\footnote{When dealing with a field that separates languages into ``pure'' and ``impure'', the religious connotations are already present. We make no apologies for the name.}. ``Disciple'' being the name of the language it compiles, and ``Disciplined'' invoking the type and effect discipline \cite{talpin:discipline} of Talpin and Jouvelot which forms the basis of our type system. Wherever possible, we have avoided creating yet another functional language (YAFL) that no-one is likely to use. Disciple's syntax is based on Haskell, and DDC itself is written in Haskell. This allows us to leverage a huge body of existing people, ideas and code.
Keeping the source and implementation languages similar will also make it easy to bootstrap DDC in future work.

As destructive update is the source of all our problems, we start with a discussion of \emph{why} it should be included in a language in the first place. Having convinced ourselves that it is really needed, we will examine how it is supported in existing functional languages, and argue that this support is inadequate. We will discuss the notion of purity and how it benefits a language. We will also consider what it means for a language supporting destructive update and other side effects to be pure, and whether the formal notion of purity is useful in practice. Disciple allows arbitrary structures to be updated, and functions to have arbitrary side effects. Instead of relying on state monads, we use a type based analysis to recover mutability, effect and data sharing information from the program being compiled. We use an intermediate language similar to System-Fc~\cite{sulzmann:system-Fc} and our analysis recovers enough information to do the same code transformation style optimisations as a highly optimising compiler such as GHC~\cite{peyton-jones:compilation-by-transformation}. We will discuss some of the practical problems with using lazy evaluation as the default method, and why space leaks are so common in lazy programs. Disciple uses strict evaluation by default, but allows the programmer to introduce laziness when desired. We use the type system to ensure that the combination of destructive update and laziness does not change the meaning of the program compared with the strict case.

This chapter outlines our approach and the reasons we have chosen it. Chapter 2 discusses the type system in detail, and Chapter 3 outlines the inference algorithm. Chapter 4 describes our core language and gives a proof of soundness for its type system. Chapter 5 summarises what we have learned so far and suggests avenues for future work.



