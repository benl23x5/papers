%!TEX root = ../Appendix.tex
\clearpage{}

\section{Combinators}
\label{s:Combinators}
Here we show the definitions of some combinators. We start with simple combinators supported by most streaming systems, and progress to more interesting combinators. Some standard combinators such as @fold@, @take@ and @append@ are missing due to the infinite nature of our streams, but could be implemented with the finite stream extension. The fact that segmented versions of these combinators can be implemented is compelling evidence of this.

Many of these combinators take a ``default'' argument, which is used to initialise the heap, but the stored value is never actually read. Ideally these could be left unspecified, or the heap left uninitialised in cases where it is never read.

\subsection{Map}
The map combinator applies a function to every element of the stream. This is some more text.

\begin{alltt}
map 
 =  \(\lambda\) (f : \(\alpha \to \beta\)) (default : \(\alpha\))
      (sIn: Stream \(\alpha\)) (sOut: Stream \(\beta\)). 
    \(\nu\) (a: \(\alpha\)) (L0..L2: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sIn }
    , outs:   { sOut }
    , heap:   { a = default }
    , label:  L0
    , instrs: { L0 = pull sIn     a  L1 []
              , L1 = push sOut (f a) L2 []
              , L2 = drop sIn        L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Filter}
Filter returns a new stream containing only the elements that satisfy some predicate.
\begin{alltt}
filter 
 =  \(\lambda\) (f : \(\alpha \to\) Bool) (default : \(\alpha\))
      (sIn: Stream \(\alpha\)) (sOut: Stream \(\alpha\)). 
    \(\nu\) (a: \(\alpha\)) (L0..L3: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sIn }
    , outs:   { sOut }
    , heap:   { a = default }
    , label:  L0
    , instrs: { L0 = pull sIn  a     L1 []
              , L1 = case   (f a)    L2 []  L3 []
              , L2 = push sOut a     L3 []
              , L3 = drop sIn        L0 [] } }
\end{code}


\vspace{12em}
% -----------------------------------------------------------------------------
\subsection{Partition}
Partition is similar to filter, but has two output streams: those that satisfy the predicate, and those that do not. Partition is an inherently push-based operation, and cannot be supported by pull streams without buffering.
\begin{alltt}
partition 
 =  \(\lambda\) (f : \(\alpha \to\) Bool) (default : \(\alpha\))
      (sIn:   Stream \(\alpha\))
      (sOut1: Stream \(\alpha\)) (sOut2: Stream \(\alpha\)). 
    \(\nu\) (a: \(\alpha\)) (L0..L4: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sIn }
    , outs:   { sOut1, sOut2 }
    , heap:   { a = default }
    , label:  L0
    , instrs: { L0 = pull sIn   a    L1 []
              , L1 = case    (f a)   L2 []  L3 []
              , L2 = push sOut1 a    L4 []
              , L3 = push sOut2 a    L4 []
              , L4 = drop sIn        L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Zip}
Zip, or zip-with, pairwise combines two input streams.
Zipping is an inherently pull-based operation.

\begin{alltt}
zipWith 
 =  \(\lambda\) (f : \(\alpha \to \beta \to \gamma\)) (default1 : \(\alpha\)) (default2 : \(\beta\))
      (sIn1: Stream \(\alpha\)) (sIn2: Stream \(\beta\))
      (sOut: Stream \(\gamma\)). 
    \(\nu\) (a: \(\alpha\)) (b : \(\beta\)) (L0..L4: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sIn1, sIn2 }
    , outs:   { sOut }
    , heap:   { a = default1, b = default2 }
    , label:  L0
    , instrs: { L0 = pull sIn1 a       L1 []
              , L1 = pull sIn2 b       L2 []
              , L2 = push sOut (f a b) L3 []
              , L3 = drop sIn1         L4 []
              , L4 = drop sIn2         L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Scan}
Scan is similar to a fold, but instead of returning a single value at the end, it returns an intermediate value for each element of the stream.

\begin{alltt}
scan 
 =  \(\lambda\) (k : \(\alpha \to \beta \to \beta\)) (z : \(\beta\)) (default : \(\alpha\))
      (sIn: Stream \(\alpha\)) (sOut: Stream \(\beta\)).
    \(\nu\) (a: \(\alpha\)) (s : \(\beta\)) (L0..L2: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sIn  }
    , outs:   { sOut }
    , heap:   { a = default, s = z }
    , label:  L0
    , instrs: { L0 = pull sIn  a   L1 []
              , L1 = push sOut s   L2 [ s = f a s ]
              , L2 = drop sIn      L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Segmented Fold}
Segmented fold performs a fold over each nested stream, using a segmented representation.
Here we are representing nested streams using one stream for the lengths of each substream, and another stream containing the values.
The output stream has the same rate as the lengths stream.
It reads a count (@c@) from the lengths stream, setting the fold state to zero (@z@).
Then it reads count times from the values stream, updating the fold state.
Afterwards, it pushes the final fold state, and continues to read a new count.

\begin{alltt}
folds 
 =  \(\lambda\) (k : \(\alpha \to \beta \to \beta\)) (z : \(\beta\)) (default : \(\alpha\))
      (sLens: Stream Nat) (sVals: Stream \(\alpha\))
      (sOut:  Stream \(\beta\)).
    \(\nu\) (c : Nat) (a: \(\alpha\)) (s : \(\beta\)) (L0..L5: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sLens, sVals }
    , outs:   { sOut }
    , heap:   { c = 0, a = default, s = z }
    , label:  L0
    , instrs: { L0 = pull sLens c   L1 [ s = z ]
              , L1 = case (c > 0)   L2 []  L4 []
              , L2 = pull sVals a   L3 []
              , L3 = drop sVals     L1 [ c = c - 1
                                       , s = k s a ]
              , L4 = push sOut  s   L5 []
              , L5 = drop sLens     L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Segmented Take}
Segmented take computes an @n@-length prefix of each nested stream.
It starts by reading a count from the lengths stream, then copies at most @n@ elements.
If there are leftovers, it pulls and discards them, then pulls the next length.

\begin{alltt}
takes 
 =  \(\lambda\) (n : Nat) (default : \(\alpha\))
      (sLens: Stream Nat) (sVals: Stream \(\alpha\))
      (oLens: Stream Nat) (oVals: Stream \(\alpha\)).
    \(\nu\) (c : Nat) (take : Nat) (ix : Nat) (a: \(\alpha\))
      (L0..L9: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { sLens, sVals }
    , outs:   { oLens, oVals }
    , heap:   { c = 0, take = 0, ix = 0, a = default }
    , label:  L0
    , instrs: { L0 = pull sLens c     L1 
                          [ ix = 0, take = min count n ]
              , L1 = push oLens take  L2 []
              , L2 = case (ix < take) L3 []  L6 []
              , L3 = pull sVals a     L4 []
              , L4 = push oVals a     L5 []
              , L5 = drop sVals       L2 [ix = ix+1]
              , L6 = case (ix < c)    L7 []  L9 []
              , L7 = pull sVals a     L8 []
              , L8 = drop sVals       L6 [ix = ix+1]
              , L9 = drop sLens       L0 [] } }
\end{code}


% -----------------------------------------------------------------------------
\subsection{Segmented Append}
Segmented append takes two segmented streams as input, and appends each nested stream.
It starts by reading a length from both lengths streams into @a@ and @b@, and pushes the sum of both lengths.
It then copies over @a@ elements from the first values stream, then copies over @b@ elements from the second values stream.

\begin{alltt}
appends 
 =  \(\lambda\) (default : \(\alpha\))
      (aLens: Stream Nat) (aVals: Stream \(\alpha\))
      (bLens: Stream Nat) (bVals: Stream \(\alpha\))
      (oLens: Stream Nat) (oVals: Stream \(\alpha\)).
    \(\nu\) (a : Nat) (b : Nat) (v: \(\alpha\)) (L0..L12: Label).
\end{alltt}
\begin{code}
    process
    { ins:    { aLens, aVals, bLens, bVals }
    , outs:   { oLens, oVals }
    , heap:   { a = 0, b = 0, v = default }
    , label:  L0
    , instrs: { L0  = pull aLens  a    L1 []
              , L1  = pull bLens  b    L2 []
              , L2  = push oLens (a+b) L3 []

              , L3  = case (a > 0)     L4 []  L7 []
              , L4  = pull aVals v     L5 []
              , L5  = push oVals v     L6 []
              , L6  = drop aVals       L3 [ a = a-1 ]

              , L7  = case (b > 0)     L8 []  L11[]
              , L8  = pull bVals v     L9 []
              , L9  = push oVals v     L10[]
              , L10 = drop bVals       L7 [ b = b-1 ]

              , L11 = drop aLens        L12[]
              , L12 = drop bLens        L0 [] } }
\end{code}

