%!TEX root = ../Main.tex

% I've hidden this from the main paper.
% We haven't said anything about DPH until now, and I think it would take too much space
% to properly explain the relationship between flow fusion and DPH.

\section{Conclusion}
We have shown that using integer linear programming to find clusterings is able to produce predictably better clusterings than heuristic and greedy approaches.
Having a predictable clustering algorithm is particularly important when combined with other transformations, such as the vectorisation done by Data Parallel Haskell~\cite{chakravarty2007data}.
In the case of Data Parallel Haskell, the actual combinators to be clustered are not written directly by the programmer, so being able to find a good clustering without the programmer tweaking the combinators is important.

One obvious shortcoming of this work is the limited selection of combinators.
Other combinators can currently be used as external computations, but this is not ideal as they will not be fused.
Combinators such as @append@, @scan@ and @slice@ would be simple to add.

Implementing @length@ is particularly interesting, as it does not require the array to be manifest, but does require some array with the same rate to be manifest.
For example, finding the length of the output of a filter can only be done after the filter is computed.
Once @length@ is implemented, more interesting functions such as @reverse@ can be implemented as a @generate@ followed by a @gather@.

For this work to be useful for Data Parallel Haskell, more combinators are required such as segmented fold and segmented map, which operate on segmented representations of nested arrays.
Rate inference will have to be adapted to handle segmented arrays, possibly using an inner and outer rates.
For example, segmented fold takes a segmented array of inner and outer rate, and returns a single array of the outer rate.
Similarly, segmented append takes two segmented arrays with the same outer rate, but different inner rates, and returns a segmented array with a new inner rate and the same outer rate.

Data flow fusion, which generates the sequential loops, must also be extended with these extra combinators.
Data flow fusion can also be extended to generate parallel loops for most combinators by simply splitting the workload among processors.
Merging the output of each loop can be performed by concatenating the results of filters, and merging the folds, assuming the fold operation is associative.

Another interesting possibility is combinators where the output order is not important.
There are two orderings for cross product: one that requires the second array to be manifest, the other requires the first array to be manifest.
It may be worthwhile to add a separate cross combinator that does not ensure which ordering is used, but instead uses the ordering that produces the best clustering.
This could be achieved in the integer linear program by requiring that at least one of the cross combinator's inputs are not fused together.

