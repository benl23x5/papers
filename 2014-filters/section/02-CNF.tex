%!TEX root = ../Main.tex

\begin{figure*}[ht!]
\begin{center}
\includegraphics[scale=0.5]{figures/ex1-compare.pdf}
\end{center}
\caption{Clusterings for normalize2 example: with stream fusion; our system; best imperative system}
\label{f:normalize2-clusterings}
\end{figure*}


% -----------------------------------------------------------------------------
\section{Combinator Normal Form}
\label{s:CombinatorNormalForm}
Input programs are expressed in \emph{Combinator Normal Form} (CNF), which is a textual description of the data flow graph. The grammar for CNF is given in Figure~\ref{f:CombinatorNormalForm}. The @normalize2@  example on the previous page is in CNF,  as is the matching data flow graph for @normalize2@ in Figure~\ref{f:normalize2-clusterings}. Our data flow graphs are similar to Loop Communication Graphs (LCGs) from related work in imperative array fusion~\cite{gao1993collective}. We name edges after the corresponding variable from the CNF form, and edges which are fusion preventing are drawn with a dash through them (as per the edge labeled @sum1@ in Figure~\ref{f:normalize2-clusterings}). In data flow graphs, we tend to elide the worker functions to combinators when they are not important to the discussion --- so we don't show the @(+)@ operator on each use of @fold@.

Clusters of operators that are fused into single imperative loops are indicated by dotted lines, and we highlight materialized arrays by drawing them in boxes. In Figure~\ref{f:normalize2-clusterings}, the variables @xs@, @ys1@ and @ys2@ are always in boxes, as these are the material input and output arrays of the program. However, in the graph on the far right hand side, @gts@ has also been materialized because in this version, the producing and consuming operators (@filter@ and @fold@) have not been fused. In Figure~\ref{f:CombinatorNormalForm}, note that the bindings have been split into those that produce scalar values ($sbind$), and those that produce array values ($abind$). These groupings are represented as open and closed arrow-heads in Figure~\ref{f:normalize2-clusterings}.

Most of our array combinators are standard, and suggestive types are given at the bottom of Figure~\ref{f:CombinatorNormalForm}. The $@map@_n$ combinator takes a worker function, $n$ arrays of the same length, and applies the worker function to all elements at the same index. As such, it is similar to Haskell's @zipWith@, with an added length restriction on the argument arrays. The @generate@ combinator takes an array length and a worker function, and creates a new array by applying the worker to each index. The @gather@ combinator takes an array of elements, an array of indices, and produces the array of elements that are positioned at each index. In Haskell, this would be @gather arr ixs = map (index arr) ixs@. The @cross@ combinator returns the cartesian product of two arrays. 

The exact form of the worker functions is left unspecified, as it is not important for the discussion. We assume workers are pure, can at least compute arithmetic functions of their scalar arguments, and index into arrays in the environment. We also assume that each CNF program considered for fusion is embedded in a larger host program which handles file IO and the like. Workers are additionally restricted so they can only directly reference the \emph{scalar} variables bound by the local CNF program, though they may reference array variables bound by the host program. All access to locally bound array variables is via the formal parameters of array combinators, which ensures that all data dependencies we need to consider for fusion are explicit in the data flow graph.

The @external@ binding invokes a host library function that can produce and consume arrays, but not be fused with other combinators. All arrays passed to and returned from host functions are fully materialised. External bindings are explicit \emph{fusion barriers}, which force arrays and scalars to be fully computed before continuing. 

Finally, note that @filter@ is only one representative size changing operator. We can handle more complex functions such as @unfold@ in our framework, but we stick with simple filtering to aid the discussion.


\input{figures/Program.tex}

