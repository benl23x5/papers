%!TEX root = ../Main.tex
\clearpage{}
\section{Related Work}

\begin{itemize}
\item Conduit, Michael Snoyman.
\item Pipes, Gabriel Gonzales.
\item Impala.
\item Hive.
\item Spark.
\end{itemize}


% The worlds of functional array programming and database management systems are undergoing a technological convergence. On the functional programing side, the performance of programs written with combinators such as @map@, @fold@ and @filter@ now compares favourably to similar programs written using loop-based code~\cite{Keller:Repa,Lippmeier:stencil,Lippmeier:guiding}. CITE vector paper. 

% On the database side, popular distributed databases systems such as Hive and SparkSQL convert queries to object langauges that also use @map@, @fold@ and @filter@ style combinators. The map-reduce paradigm is well known --- the Hive DBMS system converts incoming SQL-like queries to map-reduce jobs that are ultimately executed on the JVM (CITE). More recently, SparkSQL produces an operator graph with a wider range of combinators that allow more intermediate data to be held in memory.\footnote{...instead of written back to disk, where belongs --- says the database programmer.} Embedded langauges such as Scalding and Scoobi allow the logica operator graph for such a query to be expressed directly using @map@, @fold@ and @filter@, yet the programs execute on the same data sets as Hive and SparkSQL, further blurring the line between functional program and ``database query''.

% A common theme in these new databases is that they are intended for \emph{analytic workloads}. The queries typically read a significant fraction of the total amount of stored data, producing an enriched data product (like summing up the total clicks per month, or reporting all products sold per store). These analytic workloads are distinct from transactional workloads where many records are changed, possibly concurrently, in a fine grained manner. Transactional systems must worry about the usual ACID properties (Atomicity, Consitency, Isolation, Durability). In contrast, analytic systems can largely ignore such considerations, as they are based around non-interactive, read-only, batch style data accesses. A concrete example written is as follows, written with our library Repa Flow.


% Repa flow fills a sweet spot between the roles functional array library and analytic database. In terms of the programming model, a key feature of Repa Flow compared with Scoobi and Scalding is that the API carefully distinguishes between operators that run in constant space and those which do not. Systems based on map-reduce make implicit use of a \emph{shuffle} operator that distributes data between the compute nodes. The \emph{shuffle} operator sends data between the nodes in a data-dependent way, which can result in a skewed workload where most data is sent to a subset of nodes while the others are starved. When all source-level queries are converted into map-reduce jobs then there is no systematic way in which skew can be avoided. Taking inspiration from the work on synchronous data flow and Khan networks, we have arranged our API so that most operators execute without buffering. With Repa Flow it is easy to write programs where both buffering and data skew are avoided by construction, or admitted only in a controlled way.

% In terms of scale, our present implementation is focused on ``medium data'', meaning data which too big to fit in the main memory of a single desktop machine, but not so big that we need a distributed cluster of hundreds or thousands of machines. Hive and SparkSQL mentioned earlier are designed primarily as enterprise scale ``big data'' systems. Restricting our attention to ``medium data'' means that we can assume a single uniform shared memory address space, run the program under a single instance of the langauge runtime system, and distribute the entire system as a normal Haskell library. We can also forgo the need for external meta-data stores as used by Hive, and avoid the compilation of managing node failure. We discuss how this work could be extended to the distributed case in Section(TODO)(conclusion).


% Techniques for directly compiling such programs are at a stage where processing several hundred megabytes of data is no problem. Five to ten years ago attempting such a thing in a general purpose functional langauge like Haskell would have been a disaster, due to the overhead of boxed numeric reprentations and the inability to eliminate intermediate arrays due to poor support for mutation. Advances in functional array fusion (CITE) and polytypic data representations (CITE) has largely alleviated this problem.
