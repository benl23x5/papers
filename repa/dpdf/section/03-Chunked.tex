%!TEX root = ../Main.tex
\section{Chunked Streams}
\label{s:Chunked}
The flows we have discussed so far have operated on elements of a generic type @e@. Alhough we can instantiate our operators at atomic types such as @Char@ and @Float@, in practice to gain reasonable runtime performance we need to amortise the cost of control flow by processing a chunk of several elements at a time. We instantiate the existing generic @Sources@ and @Sinks@ types, to produce the chunked versions @CSources@ and @CSinks@:
\begin{code}
   type CSources i m e = Sources i m (Vector e)
   type CSinks   i m e = Sinks   i m (Vector e)
\end{code}

In our Haskell implementation we use the unboxed @Vector@ type from the standard @vector@ library to represent the chunks. For operators that do not inspect the actual elements, such as @drainP@ and @funnel_i@ the chunked versions are defined simply as aliases of the generic versions, but with more specific types so that the API documentation is easier to read. Other operators such as for the @folds@ family need separate implementations because their argument functions (of type (@a -> b -> a@) work on single elements rather than chunks. 


% ---------------------------------------------------------
\subsection{Intra-chunk Fusion}
Happily, the fact that our generic flow operators are written in continuation passing style means that the fusion of operators on chunked streams arises naturally from the array fusion system already implemented in the @vector@ library.

For example, the following is the defininition of the map function for sources of chunked flows. We use the existing @map_i@ operator on generic flows, and the @umap@ operator on unboxed vectors. We suppress type class constraints to save space.
\begin{code}
   cmap_i :: (a -> b) 
          -> CSource i m e -> CSource i m e
   cmap_i f ss = map_i (umap f) ss
\end{code}

Now, suppose we map a per-element function @g@ over a flow, then map another per-element function @f@ to the result. Both @f@ and @g@ apply to all elements in all streams of the flow.
\begin{code}
   cmap_i f (cmap_i g ss)
\end{code}

Lets expand the value @ss@, naming the arity component @n@ and the pull function @pulls@.
\begin{code}
   cmap_i f (cmap_i g (Sources n pulls))
\end{code}

Inlining the definition of @cmap_i@ above gives:
\begin{code}
=> map_i (umap f) (map_i (umap g) (Sources n pulls))
\end{code}

Inlining the definition of @map_i@ and simplifying then yields:
\begin{alltt}
=> Sources n (\(\lambda\)i eat eject.
     pulls i (\(\lambda\)v. eat (umap f (umap g v))) eject)
\end{alltt}
The two instances of @umap@ are now syntactically adjacent, which allows the fusion system in the vector library to fire:

\begin{alltt}
=> Sources n (\(\lambda\)i eat eject.
     pulls i (\(\lambda\)v. eat (umap (f \(\circ\) g) v)) eject)
\end{alltt}

Suppose we wish to pull some data from this flow source. We would apply the contained function to the index @i@ of the stream we are interested, as well as our own @eat@ and @eject@ functions to either to consume a chunk or indicate that there is no more data available in stream @i@. The flow source would then apply the @pulls@ function from \emph{its} own parent source to the inner continuation. If a chunk from the parent source is available, the @umap@ function will then apply the fused @f@ and @g@ to each element before passing the result to the original @eat@ function that we provided.


% ---------------------------------------------------------
\subsection{Leftovers}
When flows carry chunks instead of single elements it becomes naturally harder to write operators which consume only a few elements at a time, rather than a whole chunk at a time. Consider the @head_i@ function which splits the first element from a specified argument stream, as well as producing a flow of the leftover elements:
\begin{code}
 head_i :: i -> Sources i m a -> (a, Sources i m a)
\end{code}

Libraries like @conduit@~\cite{hackage:conduit} manage leftovers by extending the representation of stream sources with a special constructor that carries an array of leftover elements from a previous chunk, as well as the continuation to pull more chunks from the source. For Repa Flow we avoid adding more constructors to our @Source@ and @Sink@ data types, as moving away from the simple continuation passing style of the @pull@, @eat@ and @eject@ functions makes it harder to perform the program simplications that enable intra-chunk fusion. Instead operators such as @head@ produce a new flow source where the embedded @pull@ function first produces a chunk containing leftover elements before pulling more chunks from its own source. The chunk of leftover elements is stored in the closure of the pull function itself, rather than being reified into the representation of the @Source@ data type. We rely on the linearity convention from~\S\ref{s:Linearity} to ensure the argument source is not reused, as applying @head_i@ to the same source would yield the first element in the next chunk, rather than the next element after the one that was previously returned.

