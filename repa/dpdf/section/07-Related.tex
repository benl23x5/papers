%!TEX root = ../Main.tex
\section{Related Work}

\begin{itemize}
\item Iteratee Enumerator
\item Conduit, we don't have await and yield. Flows are not monad transformers.
\item Pipes
\item Machines support multiple inputs and fanout.
\item Monad par, is event flow network using IVars.
\item Impala.
\item Hive.
\item Spark.
\item Google Tensorflow
\item Lustre, Lucid sync data flow, Kahn networks.
\item StreamIt, Brook.
\item Scala streams library.
\item FRP libraries, eg reflex.
\end{itemize}


% Repa flow fills a sweet spot between the roles functional array library and analytic database. In terms of the programming model, a key feature of Repa Flow compared with Scoobi and Scalding is that the API carefully distinguishes between operators that run in constant space and those which do not. Systems based on map-reduce make implicit use of a \emph{shuffle} operator that distributes data between the compute nodes. The \emph{shuffle} operator sends data between the nodes in a data-dependent way, which can result in a skewed workload where most data is sent to a subset of nodes while the others are starved. When all source-level queries are converted into map-reduce jobs then there is no systematic way in which skew can be avoided. Taking inspiration from the work on synchronous data flow and Khan networks, we have arranged our API so that most operators execute without buffering. With Repa Flow it is easy to write programs where both buffering and data skew are avoided by construction, or admitted only in a controlled way.
